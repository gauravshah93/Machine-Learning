{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Homework\n",
    "### Problem Set 3\n",
    "### Gaurav Shah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('C:\\\\Users\\\\shahg_000\\\\Downloads\\\\data.xlsx')\n",
    "df=data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSet=df.loc[:'2002-12-31',:]\n",
    "TestSet=df.loc['2003-01-01':,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking(toBeStacked,p):\n",
    "    n=p+1\n",
    "    stackedF=pd.DataFrame()\n",
    "    temp=np.zeros(shape=(1,n))\n",
    "    for cnum in range(toBeStacked.shape[1]):\n",
    "        temp1=np.zeros(shape=(1,n))\n",
    "        for rnum in range(n,len(toBeStacked)+1):\n",
    "            temp1=np.append(temp1,[np.flip(np.array(toBeStacked.iloc[rnum-n:rnum,cnum]))],axis=0)\n",
    "        temp1=np.delete(temp1,(0),axis=0)\n",
    "        temp=np.append(temp,temp1,axis=0)\n",
    "    return(pd.DataFrame(np.delete(temp,(0),axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DummyVariables(toBeDummy):\n",
    "    p=int(toBeDummy.shape[0]/30)\n",
    "    finalDataframe = pd.DataFrame()\n",
    "    for i in range(0,29):\n",
    "        dummyframes = pd.DataFrame(data = 0, index=range(p),columns=range(28))\n",
    "        dummyframes.insert(i, \"DV\"+str(i), 1)\n",
    "        finalDataframe = finalDataframe.append(dummyframes)\n",
    "    dvAllZero = pd.DataFrame(data = 0, index=range(p),columns=range(28))\n",
    "    finalDataframe = finalDataframe.append(dvAllZero, ignore_index=True)\n",
    "    finalDataframe.drop(finalDataframe.iloc[:, 0:28], inplace = True, axis = 1) \n",
    "    finalDataframe = finalDataframe.fillna(0)\n",
    "    return(pd.concat([toBeDummy, finalDataframe], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TrainingStacked=Stacking(TrainingSet,30)\n",
    "TestStacked=Stacking(TestSet,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahg_000\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "TrainingDummyStacked=DummyVariables(TrainingStacked)\n",
    "TestDummyStacked=DummyVariables(TestStacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>DV26</th>\n",
       "      <th>DV27</th>\n",
       "      <th>DV28</th>\n",
       "      <th>DV3</th>\n",
       "      <th>DV4</th>\n",
       "      <th>DV5</th>\n",
       "      <th>DV6</th>\n",
       "      <th>DV7</th>\n",
       "      <th>DV8</th>\n",
       "      <th>DV9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.022039</td>\n",
       "      <td>-0.008141</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.039442</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>0.017648</td>\n",
       "      <td>-0.017648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.022039</td>\n",
       "      <td>-0.008141</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.039442</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>0.017648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.022039</td>\n",
       "      <td>-0.008141</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.039442</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.022039</td>\n",
       "      <td>-0.008141</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.039442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.021799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.022039</td>\n",
       "      <td>-0.008141</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.022162  0.008439 -0.014025 -0.022039 -0.008141  0.021859  0.039442   \n",
       "1 -0.016575  0.022162  0.008439 -0.014025 -0.022039 -0.008141  0.021859   \n",
       "2  0.011080 -0.016575  0.022162  0.008439 -0.014025 -0.022039 -0.008141   \n",
       "3  0.000000  0.011080 -0.016575  0.022162  0.008439 -0.014025 -0.022039   \n",
       "4  0.021799  0.000000  0.011080 -0.016575  0.022162  0.008439 -0.014025   \n",
       "\n",
       "          7         8         9  ...  DV26  DV27  DV28  DV3  DV4  DV5  DV6  \\\n",
       "0  0.014472  0.017648 -0.017648  ...   0.0   0.0   0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.039442  0.014472  0.017648  ...   0.0   0.0   0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.021859  0.039442  0.014472  ...   0.0   0.0   0.0  0.0  0.0  0.0  0.0   \n",
       "3 -0.008141  0.021859  0.039442  ...   0.0   0.0   0.0  0.0  0.0  0.0  0.0   \n",
       "4 -0.022039 -0.008141  0.021859  ...   0.0   0.0   0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   DV7  DV8  DV9  \n",
       "0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingDummyStacked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>DV26</th>\n",
       "      <th>DV27</th>\n",
       "      <th>DV28</th>\n",
       "      <th>DV3</th>\n",
       "      <th>DV4</th>\n",
       "      <th>DV5</th>\n",
       "      <th>DV6</th>\n",
       "      <th>DV7</th>\n",
       "      <th>DV8</th>\n",
       "      <th>DV9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "      <td>118740.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.020484</td>\n",
       "      <td>0.020485</td>\n",
       "      <td>0.020484</td>\n",
       "      <td>0.020487</td>\n",
       "      <td>0.020492</td>\n",
       "      <td>0.020492</td>\n",
       "      <td>0.020491</td>\n",
       "      <td>0.020494</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179506</td>\n",
       "      <td>0.179506</td>\n",
       "      <td>0.179506</td>\n",
       "      <td>0.179506</td>\n",
       "      <td>0.179506</td>\n",
       "      <td>0.179506</td>\n",
       "      <td>0.179506</td>\n",
       "      <td>0.179506</td>\n",
       "      <td>0.179506</td>\n",
       "      <td>0.179506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>-0.379490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.010210</td>\n",
       "      <td>-0.010216</td>\n",
       "      <td>-0.010227</td>\n",
       "      <td>-0.010219</td>\n",
       "      <td>-0.010230</td>\n",
       "      <td>-0.010223</td>\n",
       "      <td>-0.010230</td>\n",
       "      <td>-0.010231</td>\n",
       "      <td>-0.010227</td>\n",
       "      <td>-0.010231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.011233</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>0.011231</td>\n",
       "      <td>0.011232</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0              1              2              3  \\\n",
       "count  118740.000000  118740.000000  118740.000000  118740.000000   \n",
       "mean        0.000511       0.000510       0.000505       0.000509   \n",
       "std         0.020482       0.020484       0.020485       0.020484   \n",
       "min        -0.379490      -0.379490      -0.379490      -0.379490   \n",
       "25%        -0.010210      -0.010216      -0.010227      -0.010219   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.011233       0.011234       0.011227       0.011231   \n",
       "max         0.226528       0.226528       0.226528       0.226528   \n",
       "\n",
       "                   4              5              6              7  \\\n",
       "count  118740.000000  118740.000000  118740.000000  118740.000000   \n",
       "mean        0.000504       0.000512       0.000512       0.000509   \n",
       "std         0.020487       0.020492       0.020492       0.020491   \n",
       "min        -0.379490      -0.379490      -0.379490      -0.379490   \n",
       "25%        -0.010230      -0.010223      -0.010230      -0.010231   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.011232       0.011236       0.011236       0.011236   \n",
       "max         0.226528       0.226528       0.226528       0.226528   \n",
       "\n",
       "                   8              9  ...           DV26           DV27  \\\n",
       "count  118740.000000  118740.000000  ...  118740.000000  118740.000000   \n",
       "mean        0.000515       0.000513  ...       0.033333       0.033333   \n",
       "std         0.020494       0.020497  ...       0.179506       0.179506   \n",
       "min        -0.379490      -0.379490  ...       0.000000       0.000000   \n",
       "25%        -0.010227      -0.010231  ...       0.000000       0.000000   \n",
       "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "75%         0.011243       0.011243  ...       0.000000       0.000000   \n",
       "max         0.226528       0.226528  ...       1.000000       1.000000   \n",
       "\n",
       "                DV28            DV3            DV4            DV5  \\\n",
       "count  118740.000000  118740.000000  118740.000000  118740.000000   \n",
       "mean        0.033333       0.033333       0.033333       0.033333   \n",
       "std         0.179506       0.179506       0.179506       0.179506   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                 DV6            DV7            DV8            DV9  \n",
       "count  118740.000000  118740.000000  118740.000000  118740.000000  \n",
       "mean        0.033333       0.033333       0.033333       0.033333  \n",
       "std         0.179506       0.179506       0.179506       0.179506  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingDummyStacked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=TrainingDummyStacked.loc[:,0]\n",
    "X=TrainingDummyStacked.drop([0],axis=1)\n",
    "y_test=TestDummyStacked.loc[:,0]\n",
    "X_test=TestDummyStacked.drop([0],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_shape=(59,)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94992 samples, validate on 23748 samples\n",
      "Epoch 1/30\n",
      "94992/94992 [==============================] - 7s 74us/step - loss: 4.7347e-04 - val_loss: 3.5501e-04\n",
      "Epoch 2/30\n",
      "94992/94992 [==============================] - 7s 76us/step - loss: 4.4522e-04 - val_loss: 3.3159e-04\n",
      "Epoch 3/30\n",
      "94992/94992 [==============================] - 7s 69us/step - loss: 4.4419e-04 - val_loss: 3.2945e-04\n",
      "Epoch 4/30\n",
      "94992/94992 [==============================] - 7s 72us/step - loss: 4.4427e-04 - val_loss: 3.3201e-04\n",
      "Epoch 5/30\n",
      "94992/94992 [==============================] - 6s 67us/step - loss: 4.4306e-04 - val_loss: 3.2911e-04\n",
      "Epoch 6/30\n",
      "94992/94992 [==============================] - 7s 69us/step - loss: 4.4190e-04 - val_loss: 3.2883e-04\n",
      "Epoch 7/30\n",
      "94992/94992 [==============================] - 7s 74us/step - loss: 4.4157e-04 - val_loss: 3.2863e-04\n",
      "Epoch 8/30\n",
      "94992/94992 [==============================] - 7s 72us/step - loss: 4.4103e-04 - val_loss: 3.2944e-04\n",
      "Epoch 9/30\n",
      "94992/94992 [==============================] - 6s 68us/step - loss: 4.3976e-04 - val_loss: 3.3055e-04\n",
      "Epoch 10/30\n",
      "94992/94992 [==============================] - 6s 66us/step - loss: 4.3869e-04 - val_loss: 3.2881e-04\n",
      "Epoch 11/30\n",
      "94992/94992 [==============================] - 6s 68us/step - loss: 4.3781e-04 - val_loss: 3.3081e-04\n",
      "Epoch 12/30\n",
      "94992/94992 [==============================] - 6s 67us/step - loss: 4.3683e-04 - val_loss: 3.3033e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x273be4624a8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "model.fit(X,y, validation_split=0.2, epochs=30, \n",
    "          callbacks=[early_stopping_monitor],batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absoulte error is : 0.012856670606135746\n"
     ]
    }
   ],
   "source": [
    "y_pred_model1=model.predict(X_test)\n",
    "print(\"The mean absoulte error is :\",mean_absolute_error(y_test,y_pred_model1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(15, activation='relu', input_shape=(59,)))\n",
    "model2.add(layers.Dropout(0.3, input_shape=(59,)))\n",
    "model2.add(Dense(10, activation='relu'))\n",
    "model2.add(layers.Dropout(0.3, input_shape=(59,)))\n",
    "model2.add(Dense(5, activation='relu'))\n",
    "model2.add(layers.Dropout(0.3, input_shape=(59,)))\n",
    "model2.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "118740/118740 [==============================] - 10s 88us/step - loss: 4.4783e-04\n",
      "Epoch 2/30\n",
      "  1720/118740 [..............................] - ETA: 11s - loss: 4.1495e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahg_000\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118740/118740 [==============================] - 10s 83us/step - loss: 4.2186e-04\n",
      "Epoch 3/30\n",
      "118740/118740 [==============================] - 9s 76us/step - loss: 4.2170e-04\n",
      "Epoch 4/30\n",
      "118740/118740 [==============================] - 10s 84us/step - loss: 4.2185e-04\n",
      "Epoch 5/30\n",
      "118740/118740 [==============================] - 10s 82us/step - loss: 4.2164e-04\n",
      "Epoch 6/30\n",
      "118740/118740 [==============================] - 10s 83us/step - loss: 4.2173e-04\n",
      "Epoch 7/30\n",
      "118740/118740 [==============================] - 10s 88us/step - loss: 4.2176e-04\n",
      "Epoch 8/30\n",
      "118740/118740 [==============================] - 11s 92us/step - loss: 4.2197e-04\n",
      "Epoch 9/30\n",
      "118740/118740 [==============================] - 10s 83us/step - loss: 4.2163e-04\n",
      "Epoch 10/30\n",
      "118740/118740 [==============================] - 10s 87us/step - loss: 4.2185e-04\n",
      "Epoch 11/30\n",
      "118740/118740 [==============================] - 10s 85us/step - loss: 4.2191e-04\n",
      "Epoch 12/30\n",
      "118740/118740 [==============================] - 10s 84us/step - loss: 4.2178e-04\n",
      "Epoch 13/30\n",
      "118740/118740 [==============================] - 9s 72us/step - loss: 4.2177e-04\n",
      "Epoch 14/30\n",
      "118740/118740 [==============================] - 10s 84us/step - loss: 4.2166e-04\n",
      "Epoch 15/30\n",
      "118740/118740 [==============================] - 8s 70us/step - loss: 4.2176e-04\n",
      "Epoch 16/30\n",
      "118740/118740 [==============================] - 10s 82us/step - loss: 4.2166e-04\n",
      "Epoch 17/30\n",
      "118740/118740 [==============================] - 11s 90us/step - loss: 4.2149e-04\n",
      "Epoch 18/30\n",
      "118740/118740 [==============================] - 10s 84us/step - loss: 4.2185e-04\n",
      "Epoch 19/30\n",
      "118740/118740 [==============================] - 11s 95us/step - loss: 4.2175e-04\n",
      "Epoch 20/30\n",
      "118740/118740 [==============================] - 11s 90us/step - loss: 4.2184e-04\n",
      "Epoch 21/30\n",
      "118740/118740 [==============================] - 10s 82us/step - loss: 4.2147e-04\n",
      "Epoch 22/30\n",
      "118740/118740 [==============================] - 11s 92us/step - loss: 4.2170e-04\n",
      "Epoch 23/30\n",
      "118740/118740 [==============================] - 9s 80us/step - loss: 4.2169e-04\n",
      "Epoch 24/30\n",
      "118740/118740 [==============================] - 9s 78us/step - loss: 4.2173e-04\n",
      "Epoch 25/30\n",
      "118740/118740 [==============================] - 10s 84us/step - loss: 4.2193e-04\n",
      "Epoch 26/30\n",
      "118740/118740 [==============================] - 12s 98us/step - loss: 4.2181e-04\n",
      "Epoch 27/30\n",
      "118740/118740 [==============================] - 9s 72us/step - loss: 4.2148e-04\n",
      "Epoch 28/30\n",
      "118740/118740 [==============================] - 9s 73us/step - loss: 4.2165e-04\n",
      "Epoch 29/30\n",
      "118740/118740 [==============================] - 9s 73us/step - loss: 4.2169e-04\n",
      "Epoch 30/30\n",
      "118740/118740 [==============================] - 11s 95us/step - loss: 4.2160e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cb87b9de80>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X,y, epochs=30, callbacks=[early_stopping_monitor],batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absoulte error is : 0.012631173459715548\n"
     ]
    }
   ],
   "source": [
    "y_pred_model2=model2.predict(X_test)\n",
    "print(\"The mean absoulte error is :\",mean_absolute_error(y_test,y_pred_model2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-4250f3b933d5>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-4250f3b933d5>\"\u001b[1;36m, line \u001b[1;32m26\u001b[0m\n\u001b[1;33m    grid_search.model3.add(X,y)\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "#Credits: https://gist.github.com/mustafa-qamaruddin\n",
    "class BlockingTimeSeriesSplit():\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.8 * (stop - start)) + start\n",
    "            yield indices[start: mid], indices[mid + margin: stop]\n",
    "def l2_regularization_param(X, y):\n",
    "    btscv = BlockingTimeSeriesSplit(n_splits=5)\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {keras.regularizers.l2() : gammas}\n",
    "    grid_search = GridSearchCV(model3.add(Dense(15, activation='relu', input_shape=(59,)), param_grid, cv=btscv)\n",
    "    grid_search.model3.add(X,y)\n",
    "    grid_search.best_param_\n",
    "    return grid_search.best_param_\n",
    "l2_regularization_param(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(15, activation='relu', input_shape=(59,),kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model3.add(Dense(10, activation='relu',kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model3.add(Dense(5, activation='relu',kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model3.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "118740/118740 [==============================] - 9s 79us/step - loss: 0.0013\n",
      "Epoch 2/30\n",
      "118740/118740 [==============================] - 9s 73us/step - loss: 4.2169e-04\n",
      "Epoch 3/30\n",
      "118740/118740 [==============================] - 8s 69us/step - loss: 4.2154e-04\n",
      "Epoch 4/30\n",
      "118740/118740 [==============================] - 8s 70us/step - loss: 4.2169e-04\n",
      "Epoch 5/30\n",
      "118740/118740 [==============================] - 8s 68us/step - loss: 4.2142e-04\n",
      "Epoch 6/30\n",
      "118740/118740 [==============================] - 8s 70us/step - loss: 4.2173e-04\n",
      "Epoch 7/30\n",
      "118740/118740 [==============================] - 9s 72us/step - loss: 4.2172e-04\n",
      "Epoch 8/30\n",
      "118740/118740 [==============================] - 7s 63us/step - loss: 4.2161e-04\n",
      "Epoch 9/30\n",
      "118740/118740 [==============================] - 9s 76us/step - loss: 4.2172e-04\n",
      "Epoch 10/30\n",
      "118740/118740 [==============================] - 8s 71us/step - loss: 4.2183e-04\n",
      "Epoch 11/30\n",
      "118740/118740 [==============================] - 8s 70us/step - loss: 4.2171e-04\n",
      "Epoch 12/30\n",
      "118740/118740 [==============================] - 8s 65us/step - loss: 4.2172e-04\n",
      "Epoch 13/30\n",
      "118740/118740 [==============================] - 7s 60us/step - loss: 4.2159e-04\n",
      "Epoch 14/30\n",
      "118740/118740 [==============================] - 7s 57us/step - loss: 4.2173e-04\n",
      "Epoch 15/30\n",
      "118740/118740 [==============================] - 8s 65us/step - loss: 4.2153e-04\n",
      "Epoch 16/30\n",
      "118740/118740 [==============================] - 7s 63us/step - loss: 4.2155e-04\n",
      "Epoch 17/30\n",
      "118740/118740 [==============================] - 8s 64us/step - loss: 4.2196e-04\n",
      "Epoch 18/30\n",
      "118740/118740 [==============================] - 7s 62us/step - loss: 4.2166e-04\n",
      "Epoch 19/30\n",
      "118740/118740 [==============================] - 7s 58us/step - loss: 4.2178e-04\n",
      "Epoch 20/30\n",
      "118740/118740 [==============================] - 7s 60us/step - loss: 4.2149e-04\n",
      "Epoch 21/30\n",
      "118740/118740 [==============================] - 11s 91us/step - loss: 4.2158e-04\n",
      "Epoch 22/30\n",
      "118740/118740 [==============================] - 16s 132us/step - loss: 4.2176e-04\n",
      "Epoch 23/30\n",
      "118740/118740 [==============================] - 10s 84us/step - loss: 4.2167e-04\n",
      "Epoch 24/30\n",
      "118740/118740 [==============================] - 9s 72us/step - loss: 4.2160e-04\n",
      "Epoch 25/30\n",
      "118740/118740 [==============================] - 7s 58us/step - loss: 4.2175e-04\n",
      "Epoch 26/30\n",
      "118740/118740 [==============================] - 9s 73us/step - loss: 4.2197e-04\n",
      "Epoch 27/30\n",
      "118740/118740 [==============================] - 9s 72us/step - loss: 4.2183e-04\n",
      "Epoch 28/30\n",
      "118740/118740 [==============================] - 7s 61us/step - loss: 4.2158e-04\n",
      "Epoch 29/30\n",
      "118740/118740 [==============================] - 8s 64us/step - loss: 4.2175e-04\n",
      "Epoch 30/30\n",
      "118740/118740 [==============================] - 7s 61us/step - loss: 4.2181e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cb90ee6dd8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X,y,epochs=30, callbacks=[early_stopping_monitor],batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absoulte error is : 0.012742328417695684\n"
     ]
    }
   ],
   "source": [
    "y_pred_model3=model3.predict(X_test)\n",
    "print(\"The mean absoulte error is :\",mean_absolute_error(y_test,y_pred_model3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary=y\n",
    "y_test_binary=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary[y_binary<=0]=0\n",
    "y_binary[y_binary>0]=1\n",
    "y_test_binary[y_test_binary<=0]=0\n",
    "y_test_binary[y_test_binary>0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "y_binary = ohe.fit_transform(np.array(y_binary).reshape(-1,1)).toarray()\n",
    "y_test_binary=ohe.fit_transform(np.array(y_test_binary).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(15, activation='relu', input_shape=(59,)))\n",
    "model4.add(layers.Dropout(0.3, input_shape=(59,)))\n",
    "model4.add(Dense(10, activation='relu'))\n",
    "model4.add(layers.Dropout(0.3, input_shape=(59,)))\n",
    "model4.add(Dense(5, activation='relu'))\n",
    "model4.add(layers.Dropout(0.3, input_shape=(59,)))\n",
    "model4.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "118740/118740 [==============================] - 10s 82us/step - loss: 0.6901 - accuracy: 0.5313\n",
      "Epoch 2/30\n",
      "  1700/118740 [..............................] - ETA: 11s - loss: 0.6877 - accuracy: 0.5418"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahg_000\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118740/118740 [==============================] - 10s 80us/step - loss: 0.6900 - accuracy: 0.5311\n",
      "Epoch 3/30\n",
      "118740/118740 [==============================] - 9s 79us/step - loss: 0.6900 - accuracy: 0.5323\n",
      "Epoch 4/30\n",
      "118740/118740 [==============================] - 9s 77us/step - loss: 0.6898 - accuracy: 0.5327\n",
      "Epoch 5/30\n",
      "118740/118740 [==============================] - 9s 79us/step - loss: 0.6898 - accuracy: 0.5307\n",
      "Epoch 6/30\n",
      "118740/118740 [==============================] - 9s 79us/step - loss: 0.6901 - accuracy: 0.5310\n",
      "Epoch 7/30\n",
      "118740/118740 [==============================] - 9s 77us/step - loss: 0.6899 - accuracy: 0.5311\n",
      "Epoch 8/30\n",
      "118740/118740 [==============================] - 9s 77us/step - loss: 0.6898 - accuracy: 0.5319\n",
      "Epoch 9/30\n",
      "118740/118740 [==============================] - 9s 80us/step - loss: 0.6897 - accuracy: 0.5323\n",
      "Epoch 10/30\n",
      "118740/118740 [==============================] - 9s 79us/step - loss: 0.6896 - accuracy: 0.5321\n",
      "Epoch 11/30\n",
      "118740/118740 [==============================] - 10s 81us/step - loss: 0.6899 - accuracy: 0.5318\n",
      "Epoch 12/30\n",
      "118740/118740 [==============================] - 13s 106us/step - loss: 0.6896 - accuracy: 0.5317\n",
      "Epoch 13/30\n",
      "118740/118740 [==============================] - 14s 118us/step - loss: 0.6896 - accuracy: 0.5324\n",
      "Epoch 14/30\n",
      "118740/118740 [==============================] - 13s 113us/step - loss: 0.6897 - accuracy: 0.5319\n",
      "Epoch 15/30\n",
      "118740/118740 [==============================] - 13s 112us/step - loss: 0.6895 - accuracy: 0.5327\n",
      "Epoch 16/30\n",
      "118740/118740 [==============================] - 13s 113us/step - loss: 0.6895 - accuracy: 0.5335\n",
      "Epoch 17/30\n",
      "118740/118740 [==============================] - 14s 118us/step - loss: 0.6894 - accuracy: 0.5345\n",
      "Epoch 18/30\n",
      "118740/118740 [==============================] - 13s 113us/step - loss: 0.6894 - accuracy: 0.5332\n",
      "Epoch 19/30\n",
      "118740/118740 [==============================] - 14s 119us/step - loss: 0.6893 - accuracy: 0.5323\n",
      "Epoch 20/30\n",
      "118740/118740 [==============================] - 14s 115us/step - loss: 0.6893 - accuracy: 0.5335\n",
      "Epoch 21/30\n",
      "118740/118740 [==============================] - 14s 114us/step - loss: 0.6894 - accuracy: 0.5324\n",
      "Epoch 22/30\n",
      "118740/118740 [==============================] - 14s 122us/step - loss: 0.6894 - accuracy: 0.5332\n",
      "Epoch 23/30\n",
      "118740/118740 [==============================] - 13s 111us/step - loss: 0.6893 - accuracy: 0.5313\n",
      "Epoch 24/30\n",
      "118740/118740 [==============================] - 14s 117us/step - loss: 0.6892 - accuracy: 0.5318\n",
      "Epoch 25/30\n",
      "118740/118740 [==============================] - 12s 103us/step - loss: 0.6893 - accuracy: 0.5329\n",
      "Epoch 26/30\n",
      "118740/118740 [==============================] - 12s 99us/step - loss: 0.6894 - accuracy: 0.5326\n",
      "Epoch 27/30\n",
      "118740/118740 [==============================] - 10s 81us/step - loss: 0.6889 - accuracy: 0.5334\n",
      "Epoch 28/30\n",
      "118740/118740 [==============================] - 10s 80us/step - loss: 0.6892 - accuracy: 0.5322\n",
      "Epoch 29/30\n",
      "118740/118740 [==============================] - 9s 80us/step - loss: 0.6891 - accuracy: 0.5336\n",
      "Epoch 30/30\n",
      "118740/118740 [==============================] - 10s 82us/step - loss: 0.6887 - accuracy: 0.5346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x273cd29a2e8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X,y_binary, epochs=30, callbacks=[early_stopping_monitor],batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_model4=model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting predictions to label\n",
    "y_pred_convert = list()\n",
    "for i in range(len(y_pred_model4)):\n",
    "    y_pred_convert.append(np.argmax(y_pred_model4[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "y_test_convert = list()\n",
    "for i in range(len(y_test_binary)):\n",
    "    y_test_convert.append(np.argmax(y_test_binary[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 49.60966954978931\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is:', accuracy_score(y_pred_convert,y_test_convert)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
